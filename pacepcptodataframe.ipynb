{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSO Extratropical Prediction Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "The scientific goal of this project is to investigate the impact of the extratropics on ENSO predictability and prediction at 1-year lead times. Previous work of mine (add references) as well as many others (add references), have demontrated a link between the extratropics and ENSO development. Many features (predictors) have been identified and they are highly correlated with each other.  Can we identify a better feature or set of features by learning from all of the data rather than a priori choosing features? Can we use this to help us understand the physical and dynamical processes by which the extratropics impact development of ENSO?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do we want to predict?\n",
    "\n",
    "We want to predict Eastern Pacific or Central Pacific ENSO Events in Dec-Jan-Feb (DJF1) from the previous Dec-Jan-Feb (DJF0).  This is defined by indices, referred to as CP for Central Pacific or EP for Eastern Pacific. \n",
    "\n",
    "As a regression problem, we would just predict the value of the CP or EP Index in DJF1\n",
    "\n",
    "As a classification problem, we would define the predictand as:\n",
    "If the index is >=0.5 for DJF1, then we have a CP or EP El Nino (warm event)\n",
    "If the index is <=-0.5 for DJF1, then we have a CP or EP La Nina (cold event)\n",
    "\n",
    "For the purposes of this notebook, will write out the value of the CP or EP index to allow for flexibility in how we want to formulate the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How will we predict it?\n",
    "\n",
    "Features (predictors)\n",
    ":The features for this problem are detrended anomalies of Sea Surface Temperature (SST), sea level pressure (SLP), zonal wind stress (TAUX), zonal wind at 10m (UWND), and meridional wind at 10m (VWND) from observations based datasets at every gridpoint in the Pacific region (65S-85N ;100E-70W). SST and TAUX fields are defined only over the ocean with land points set as np.nan.  SLP, UWND, and VWND are defined over the entire domain (land and ocean).  The correlation with the CP and EP ENSO indices has been removed via linear regression.The features have not been normalized and will likely need to be because the have different scales and variance.\n",
    "\n",
    "Predictand\n",
    ": Normalized values of the CP and EP ENSO indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Reference\n",
    "1. SST is from NOAA/ERSSTv3b (1x1) 181x89\n",
    "2. SLP from NCEP Reanalysis 1 (2.5x2.5) 73x144\n",
    "3. TAUX from NCEP Reanalysis 1 Gaussian Grid 94x192\n",
    "4. UWND from NCEP Reanalysis 1 Gaussian Grid 94x192\n",
    "5. VWND from NCEP Reanalysis 1 Gaussian Grid 94x192\n",
    "\n",
    "All data are interpolated to the 2.5x2.5 deg grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook will:\n",
    "1. read in the features and predictands from netcdf as monthly data\n",
    "2. Extract the Pacific from the features datasets\n",
    "3. Calculate and extract the DJF0 seasonal averages for the features and the DJF1 seasonal averages from the predictand\n",
    "4. convert the data to a Pandas DataFrame\n",
    "5.  write out as a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xesmf as xe\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the file that has the common grid we will interpolate other fields to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridPath='/project/predictability/kpegion/rmenso/data/obs/'\n",
    "gridFile='NCEPR1.slp.anom.detrend.SEAS.globalreg.1948-2014.nc'\n",
    "ds_grid=xr.open_dataset(gridPath+gridFile, decode_times=False)\n",
    "ds_out = xr.Dataset({'lat': ds_grid['lat'],\n",
    "                     'lon': ds_grid['lon'],})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a list of the variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames=['slp','uflx','uwnd','vwnd','sst']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup path and filenames for the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath2='/project/predictability/kpegion/rmenso/data/obs/'\n",
    "fnames=['NCEPR1.slp.anom.detrend.SEAS.globalreg.1948-2014.nc',\n",
    "        'NCEPR1.uflx.anom.detrend.SEAS.globalreg.1948-2014.nc',\n",
    "        'NCEPR1.uwnd.anom.detrend.SEAS.globalreg.1948-2014.nc',\n",
    "        'NCEPR1.vwnd.anom.detrend.SEAS.globalreg.1948-2014.nc',\n",
    "        'ERSST.sst.anom.detrend.SEAS.globalreg.1948-2014.nc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data files for the predictors (features), interpolate to common grid, create a list of xarray.Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwrite existing file: bilinear_73x144_73x144.nc \n",
      " You can set reuse_weights=True to save computing time.\n"
     ]
    }
   ],
   "source": [
    "# Create empty list for storing xarray.Datasets\n",
    "ds_list=[]\n",
    "\n",
    "# Loop over all the variables and files\n",
    "for f,v in zip(fnames,varnames):\n",
    "\n",
    "    # Read in the data\n",
    "    dsF=xr.open_dataset(dataPath2+f, decode_times=False)\n",
    "    \n",
    "    # Rename the DataArray to the variable name\n",
    "    dsF=dsF.rename({'DJF':v})\n",
    "    \n",
    "    # Regrid the data to the common grid\n",
    "    regridder = xe.Regridder(dsF, ds_out, 'bilinear')\n",
    "    ds_out = regridder(dsF)  \n",
    "    \n",
    "    # Set land missing values to NaN for SST\n",
    "    if (v=='sst'):\n",
    "        ds_out=ds_out.where(ds_out['sst']<9999,np.nan)\n",
    "    \n",
    "    # Append this xarray.Dataset to the list\n",
    "    ds_list.append(ds_out[v])\n",
    "\n",
    "# Clean up regridding weight file\n",
    "regridder.clean_weight_file() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the path and file for the predictands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath1='/project/predictability/kpegion/rmenso/data/analysis/enso/'\n",
    "fnamecp='cp.pc.ERSST.SEAS.nc'\n",
    "fnameep='ep.pc.ERSST.SEAS.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the predictands and append to the xarray.Dataset list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_cp=xr.open_dataset(dataPath1+fnamecp, decode_times=False).squeeze()\n",
    "ds_ep=xr.open_dataset(dataPath1+fnameep, decode_times=False).squeeze()\n",
    "\n",
    "ds_cp=ds_cp.rename({'djf1':'cp'})\n",
    "ds_ep=ds_ep.rename({'djf1':'ep'})\n",
    "\n",
    "ds_list.append(ds_cp['cp'])\n",
    "ds_list.append(ds_ep['ep'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all the xarray.Dataset variables into a single xarray.Dataset and assign the date/times properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=xr.merge(ds_list)   \n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the Pacific Ocean region from 65S to 85N and 100E to 70W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pac=ds.sel(lat=slice(-65,85),lon=slice(100,290))\n",
    "ds_pac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(ds_pac['sst'][0,:,:])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd=ds_pac.to_dataframe().round(5)\n",
    "pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_csv('/scratch/kpegion/pacocnDJFcpepDJF1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aoes)",
   "language": "python",
   "name": "aoes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
